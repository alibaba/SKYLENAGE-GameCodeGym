# SKYLENAGE-GameCodeGym

ä»£ç å¤§è¯­è¨€æ¨¡å‹åœ¨ç¼–ç¨‹ä»»åŠ¡ä¸­å±•ç°å‡ºäº†å“è¶Šçš„èƒ½åŠ›ï¼Œç„¶è€Œç°æœ‰çš„åŸºå‡†æµ‹è¯•ä¸»è¦èšç„¦äºå•ä¸€æ¨¡æ€ï¼Œè€Œéè§†è§‰åŒ–çš„æ¸¸æˆå¼€å‘ã€‚å¤šæ•°ç°æœ‰çš„ä»£ç ç±»åŸºå‡†æµ‹è¯•ä»…è¯„ä¼°è¯­æ³•æ­£ç¡®æ€§å’Œæ‰§è¡Œå‡†ç¡®æ€§ï¼Œå´å¿½ç•¥äº†è¯¸å¦‚å¯ç©æ€§ã€è§†è§‰ç¾æ„Ÿå’Œç”¨æˆ·å‚ä¸åº¦ç­‰å¯¹çœŸå®åº”ç”¨è‡³å…³é‡è¦çš„æ¸¸æˆç‰¹å®šæŒ‡æ ‡ã€‚
ä¸ºå¼¥åˆæ¨¡å‹èƒ½åŠ›ä¸å®é™…æ¸¸æˆå¼€å‘éœ€æ±‚ä¹‹é—´çš„å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº† SKYLENAGE-GameCodeGym (V-GameGym)ï¼Œä¸€ä¸ªç»¼åˆæ€§çš„åŸºå‡†æµ‹è¯•é›†ï¼ŒåŒ…å« 2,219 ä¸ªé«˜è´¨é‡æ ·æœ¬ï¼Œè¦†ç›– 100 ä¸ªæºè‡ªçœŸå®ä»“åº“çš„ä¸»é¢˜ç°‡ã€‚æˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§æ–°é¢–çš„åŸºäºèšç±»çš„æ•°æ®æ•´ç†æ–¹æ³•ï¼Œä»¥ç¡®ä¿æ ·æœ¬çš„å¤šæ ·æ€§å’Œç»“æ„å®Œæ•´æ€§ã€‚
æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªå¤šæ¨¡æ€è¯„ä¼°æ¡†æ¶ï¼Œæ„å»ºäº†ç”±è‡ªåŠ¨åŒ– LLM é©±åŠ¨çš„å¯è§†åŒ–ä»£ç åˆæˆæµç¨‹ï¼Œå¹¶åœ¨å®Œæ•´çš„ UI æ²™ç›’ç¯å¢ƒä¸­è¿›è¡Œå®éªŒã€‚æˆ‘ä»¬çš„å¤§è§„æ¨¡åˆ†æè¡¨æ˜ï¼Œè¯¥è¯„æµ‹é›†æœ‰æ•ˆåœ°ç¼©å°äº†ä»£ç ç”Ÿæˆå‡†ç¡®æ€§ä¸å®é™…æ¸¸æˆå¼€å‘å·¥ä½œæµä¹‹é—´çš„å·®è·ï¼Œèƒ½å¤Ÿä¸ºè§†è§‰åŒ–ç¼–ç¨‹å’Œäº¤äº’å…ƒç´ ç”Ÿæˆæä¾›å¯é‡åŒ–çš„è´¨é‡æŒ‡æ ‡ã€‚

Code large language models have demonstrated outstanding capabilities in programming tasks. However, existing benchmarks primarily focus on single modalities rather than visual game development. Most code-related benchmarks only evaluate syntax correctness and execution accuracy, while overlooking game-specific metricsâ€”such as playability, visual aesthetics, and user engagementâ€”that are critical for real-world applications.
To bridge the gap between model capabilities and practical game development requirements, we propose SKYLENAGE-GameCodeGym (V-GameGym), a comprehensive benchmark comprising 2,219 high-quality samples across 100 thematic clusters derived from real-world repositories. We adopt a novel clustering-based data curation methodology to ensure both diversity and structural completeness.
Furthermore, we introduce a multimodal evaluation framework with an automated, LLM-driven pipeline for visual code synthesis, conducted within a complete UI sandbox environment. Our large-scale analysis shows that this benchmark effectively narrows the gap between code generation accuracy and practical game development workflows, providing quantifiable quality metrics for visual programming and interactive element generation.

## ğŸ® Overview

V-GameGym is an open-source project designed to evaluate and benchmark the capabilities of Large Language Models in generating functional, playable games using the Pygame library. The framework provides tools for automatic game generation, execution, evaluation, and visual recording of gameplay.

## âœ¨ Features

- **Automatic Game Generation**: Generate Pygame games from natural language requirements using LLMs
- **Game Evaluation**: Comprehensive evaluation system with scoring metrics
- **Screenshot Recording**: Automated screenshot capture during game execution
- **Video Generation**: Create gameplay videos from recorded screenshots
- **Testset Management**: Built-in testset with diverse game examples
- **Multi-processing Support**: Parallel processing for efficient evaluation

## ğŸ“ Project Structure

```
V-GameGym-opensource/
â”œâ”€â”€ game_evaluator.py          # Main evaluation script
â”œâ”€â”€ generate_pygame_codes.py   # Game generation utilities
â”œâ”€â”€ screenshot_recorder.py     # Screenshot and video recording
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.json           # LLM client configuration
â”œâ”€â”€ gamegym_testset/
â”‚   â”œâ”€â”€ gamegym_testset.jsonl # Test cases dataset
â”‚   â””â”€â”€ files/                # Generated game files and media
â””â”€â”€ V_GameGym.pdf             # Research paper
```

## ğŸš€ Getting Started

### Prerequisites

- Python 3.1+
- Pygame
- OpenAI API access or compatible LLM endpoint

### Required Dependencies

```bash
pip install pygame numpy pillow openai tqdm jsonlines
```

### Configuration

1. Edit `config/config.json` to set your LLM API configuration:

```json
{
    "client_config": {
        "api_key": "your-api-key",
        "base_url": "your-llm-endpoint",
        "timeout": 7200,
        "max_retries": 10
    },
    "chat_config": {
        "model": "your-model-name",
        "temperature": 0.7,
        "max_tokens": 8192
    }
}
```

## ğŸ“Š Usage

### Game Generation

Generate Pygame games from text requirements:

```bash
python generate_pygame_codes.py --config config/config.json --input requirements.jsonl --output generated_games.jsonl
```

### Game Evaluation

Evaluate generated games with automatic execution and recording:

```bash
python game_evaluator.py --input games.jsonl --output results.jsonl --record-screenshots --generate-videos
```

### Screenshot Recording

Record gameplay screenshots and generate videos:

```bash
python screenshot_recorder.py --game-file game.py --duration 10 --fps 5
```

## ğŸ¯ Testset

The project includes a comprehensive testset (`gamegym_testset/gamegym_testset.jsonl`) with diverse game examples:

- **Puzzle Games**: Sliding puzzle, Tetris-style games
- **Action Games**: Frogger-like crossing games, dodge games
- **Sports Games**: Pong-style paddle games
- **Arcade Games**: Various classic arcade game implementations

Each test case includes:
- Game requirements description
- Generated Python code
- Execution results and metadata
- Screenshots and gameplay videos

## ğŸ”§ Key Components

### Code Generator (`generate_pygame_codes.py`)
- Interfaces with LLMs to generate game code
- Handles prompt engineering for game requirements
- Supports batch processing with multiprocessing
- Includes error handling and retry mechanisms

### Screenshot Recorder (`screenshot_recorder.py`)
- Automated screenshot capture during game execution
- Video generation from screenshot sequences
- Configurable frame rates and recording duration
- Optimized file formats for storage efficiency

### Game Evaluator (`game_evaluator.py`)
- Executes generated games in isolated environments
- Captures runtime errors and execution metrics
- Records screenshots at regular intervals
- Generates quality scores based on execution success

## ğŸ¤ Contributing

We welcome contributions to improve V-GameGym! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is released under the MIT License. See the [LICENSE](LICENSE) file for details.

## ğŸ“š Citation

If you use V-GameGym in your research, please cite:

```bibtex
```

## ğŸ™ Acknowledgments

- Thanks to the Pygame community for the excellent game development framework
- OpenAI and other LLM providers for enabling automated code generation
- Contributors and researchers in the field of automated programming

---

**Note**: This is an open-source research project. Game generation quality may vary depending on the LLM model and configuration used.